{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0da4a22d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21260\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json\n",
    "\n",
    "path = \"/Users/[editted]/Desktop/compSoc/datasets/indeed_scraped_data/job_url_data\"\n",
    "\n",
    "# print (len(path)) #77\n",
    "\n",
    "d = {}\n",
    "\n",
    "for filename in glob.glob(os.path.join(path, '*.csv')): #for each file in job_url_data\n",
    "    date = filename[100:107] #77 + 23, the index where the date starts in each file\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line[:len(line)-1] #gets rid of /n\n",
    "            if line in d:\n",
    "                if date < d[line]: #replaces with smallest date\n",
    "                    d[line] = str(date)\n",
    "            elif line not in d and \".com\" in line: d[line] = str(date) #else adds to dictionary, gets rid of extra row\n",
    "    \n",
    "os.chdir(\"/Users/[editted]/Desktop/compSoc/datasets/indeed_scraped_data\")\n",
    "\n",
    "json_obj = json.dumps(d, indent = 4)\n",
    "\n",
    "with open(\"jobs.json\", \"w\") as outFile:\n",
    "    outFile.write(json_obj)\n",
    "    \n",
    "print (len(d)) #21260 unique job urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8b906",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are 21260 unique job urls in our database, collected between 5/17 and 5/23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33f1eb9b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15987, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.chdir(\"/Users/[editted]/Desktop/compSoc/datasets/indeed_scraped_data/job_info_data\")\n",
    "path = \"/Users/[editted]/Desktop/compSoc/datasets/indeed_scraped_data/job_info_data\"\n",
    "\n",
    "fol = os.listdir(path)\n",
    "dfs = []\n",
    "                \n",
    "for f in fol:\n",
    "    if '.csv' in f:\n",
    "        df = pd.read_csv(f)\n",
    "        df.rename(columns = {\"lnks_link\": \"link\", \"lnks_job_title\": \"job_title\", \n",
    "                             \"lnks_job_description\": \"job_description\", \"lnks_company\": \"company\",\n",
    "                             \"lnks_company_url\": \"company_url\", \"lnks_company_location\": \n",
    "                             \"company_location\"}, inplace = True)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    elif '.json' in f: #for json files only\n",
    "        with open(f) as file:\n",
    "            df_list = []\n",
    "            data = json.load(file)\n",
    "            for i in data: #keep all entries with all fields filled out\n",
    "                for item in data[i]:\n",
    "                    if len(item) == 6:\n",
    "                        df_list.append(item)\n",
    "        df = pd.DataFrame(df_list) #convert to pandas dataframe\n",
    "        dfs.append(df)\n",
    "\n",
    "indeed_df = pd.concat(dfs)\n",
    "indeed_df.dropna(subset = [\"job_title\", \"job_description\"], inplace = True)\n",
    "indeed_df.drop_duplicates(subset = [\"link\"], inplace = True)\n",
    "print(indeed_df.shape)\n",
    "\n",
    "os.chdir(\"/Users/[editted]/Desktop/compSoc/datasets/indeed_scraped_data\")\n",
    "indeed_df.to_csv(\"clean_indeed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86045f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are 15987 unique job offerings from 5/17 to 5/23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3e584e58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link  not null count: 21260\n",
      "date  not null count: 21260\n",
      "job_title  not null count: 15816\n",
      "company  not null count: 14153\n",
      "company_url  not null count: 14153\n",
      "company_location  not null count: 15816\n",
      "job_description  not null count: 15816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5172022</td>\n",
       "      <td>3225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5182022</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5192022</td>\n",
       "      <td>3343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5202022</td>\n",
       "      <td>4123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5212022</td>\n",
       "      <td>1726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5222022</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date  link\n",
       "0  5172022  3225\n",
       "1  5182022  1220\n",
       "2  5192022  3343\n",
       "3  5202022  4123\n",
       "4  5212022  1726\n",
       "5  5222022   516"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "os.chdir(\"/Users/[editted]/Desktop/compSoc/datasets/indeed_scraped_data\")\n",
    "path = \"/Users/[editted]/Desktop/compSoc/datasets/indeed_scraped_data\"\n",
    "\n",
    "with open(\"jobs.json\") as file:\n",
    "    df_list = []\n",
    "    data = json.load(file)\n",
    "    url_list = data.items()\n",
    "    for i in url_list:\n",
    "        df_list.append(i)\n",
    "    url_df = pd.DataFrame(df_list)\n",
    "url_df.rename(columns = {0: \"link\", 1: \"date\"}, inplace = True)\n",
    "\n",
    "clean_df = pd.read_csv(\"clean_indeed.csv\")\n",
    "clean_df\n",
    "\n",
    "df = url_df.merge(clean_df, how = \"left\", on=\"link\")\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col, ' not null count:', df[col].notnull().sum()) #5444 not matched, 1666 had null companies/urls originally\n",
    "\n",
    "df[\"match_ind\"] = None\n",
    "df[\"match_ind\"][df[\"job_title\"].isna()] = \"unmatched\"\n",
    "df[\"match_ind\"][df[\"job_title\"].notnull()] = \"matched\"\n",
    "\n",
    "df2 = df.groupby([\"match_ind\", \"date\"]).agg({'link': 'count'}).reset_index()\n",
    "df2 #most of the unmatched are on the last day, there are much fewer job offerings available in later days\n",
    "\n",
    "df3 = df.dropna().groupby([\"date\"]).agg({'link': 'count'}).reset_index()\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fbc3b6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Percent matched = #not null/#null = 66.5%\n",
    "\n",
    "Missing data are primarily on 5/17 and 5/23.\n",
    "\n",
    "Matched data varies greatly each day, with the highest frequency occurring on 5/20/2022.\n",
    "\n",
    "Complete job listings also follow the same pattern as the matched data, varying greatly each day and decreasing sharply after the peak.\n",
    "\n",
    "I would not consider these results to be particularly bad with respect to data quality; however, I would need to see data from other weeks to confirm that this was due to random noise and not a consistent trend. If it is a trend, this could pose a problemâ€”the data we collect in later days of the week is more likely to be incomplete, which means our analysis will more likely focus on data from specific days of the week. This could introduce bias; for example, if these jobs are more likely to be posted on weekend days, our analysis would now not capture that effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}